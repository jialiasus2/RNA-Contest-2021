{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: paddlehelix in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehelix) (0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehelix) (1.1.5)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehelix) (2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehelix) (1.16.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx->paddlehelix) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->paddlehelix) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->paddlehelix) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->paddlehelix) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->paddlehelix) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlehelix) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlehelix) (0.14.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlehelix\r\n",
    "# import sys \r\n",
    "# sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750\n",
      "250\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "# 读取训练集、验证集和测试集数据\r\n",
    "from utils import ReadData, ReadFasta, List2Dict, TRAIN_TXT, DEV_TXT, TEST_TXT, FOLDC_FEATURE_FILE, CONTRAFOLD_FEATURE_FILES\r\n",
    "\r\n",
    "train_datas = ReadData(TRAIN_TXT, True)\r\n",
    "print(len(train_datas))\r\n",
    "dev_datas = ReadData(DEV_TXT, True)\r\n",
    "print(len(dev_datas))\r\n",
    "test_datas = ReadData(TEST_TXT, False)\r\n",
    "print(len(test_datas))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 100 861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([263., 194., 150., 135., 145., 105., 156., 215., 222., 241., 208.,\n",
       "        170., 153., 159., 143., 141., 157., 177., 236., 208., 181., 222.,\n",
       "        244., 248., 264., 251.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   6.,   0.,   0.,  22.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   3.,   0.,   3.]),\n",
       " array([100.  , 115.22, 130.44, 145.66, 160.88, 176.1 , 191.32, 206.54,\n",
       "        221.76, 236.98, 252.2 , 267.42, 282.64, 297.86, 313.08, 328.3 ,\n",
       "        343.52, 358.74, 373.96, 389.18, 404.4 , 419.62, 434.84, 450.06,\n",
       "        465.28, 480.5 , 495.72, 510.94, 526.16, 541.38, 556.6 , 571.82,\n",
       "        587.04, 602.26, 617.48, 632.7 , 647.92, 663.14, 678.36, 693.58,\n",
       "        708.8 , 724.02, 739.24, 754.46, 769.68, 784.9 , 800.12, 815.34,\n",
       "        830.56, 845.78, 861.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "import time\r\n",
    "from tqdm import tqdm\r\n",
    "# import numba\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import pahelix.toolkit.linear_rna as linear_rna\r\n",
    "\r\n",
    "np.random.seed(2021)\r\n",
    "\r\n",
    "# 对rna长度和碱基分布进行统计分析\r\n",
    "all_seq = []\r\n",
    "all_stru = []\r\n",
    "all_length = []\r\n",
    "all_prob = []\r\n",
    "prob_dict = {\r\n",
    "    'A':[],\r\n",
    "    'C':[],\r\n",
    "    'G':[],\r\n",
    "    'U':[],\r\n",
    "    '(':[],\r\n",
    "    ')':[],\r\n",
    "    '.':[],\r\n",
    "}\r\n",
    "for data in train_datas+dev_datas+test_datas:\r\n",
    "    all_seq+=data[1]\r\n",
    "    all_stru += data[2]\r\n",
    "    all_length += [len(data[1]),]\r\n",
    "    if len(data)>3:\r\n",
    "        all_prob+=data[3]\r\n",
    "        for s,d,p in zip(data[1], data[2], data[3]):\r\n",
    "            prob_dict[s].append(p)\r\n",
    "            prob_dict[d].append(p)\r\n",
    "print('length:', min(all_length), max(all_length))\r\n",
    "plt.hist(all_length, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.6285336177922761\n",
      "C 0.28163276316208524\n",
      "G 0.3009997370205152\n",
      "U 0.3637796560772179\n",
      "( 0.14009909802542647\n",
      ") 0.1424230962719017\n",
      ". 0.8058003383427836\n"
     ]
    }
   ],
   "source": [
    "# 碱基比例分布和结构比例分布\r\n",
    "for k, v in prob_dict.items():\r\n",
    "    print(k, sum(v)/len(v))\r\n",
    "# plt.figure(), plt.hist(prob_dict['A'])\r\n",
    "# plt.figure(), plt.hist(prob_dict['C'])\r\n",
    "# plt.figure(), plt.hist(prob_dict['G'])\r\n",
    "# plt.figure(), plt.hist(prob_dict['U'])\r\n",
    "# plt.figure(), plt.hist(prob_dict['('])\r\n",
    "# plt.figure(), plt.hist(prob_dict[')'])\r\n",
    "# plt.figure(), plt.hist(prob_dict['.'])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'G': 469293, 'A': 423831, 'U': 362568, 'C': 356323})\n",
      "Counter({'.': 619535, '(': 496240, ')': 496240})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([819693.,  51007.,  29374.,  23551.,  21622.,  20957.,  22012.,\n",
       "         29433.,  48337., 496750.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对训练集标签分布进行直方图分析\r\n",
    "from collections import Counter\r\n",
    "seq_cnt = Counter(all_seq)\r\n",
    "stru_cnt = Counter(all_stru)\r\n",
    "print(seq_cnt)\r\n",
    "print(stru_cnt)\r\n",
    "# print('prob:', min(all_prob), max(all_prob), all_prob[:20])\r\n",
    "plt.hist(all_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcb11bcf2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 分析rna长度和平均不成对概率之间的关系\r\n",
    "X = []\r\n",
    "Y = []\r\n",
    "for data in train_datas+dev_datas:\r\n",
    "    X.append(len(data[1]))\r\n",
    "    Y.append(sum(data[3])/len(data[3]))\r\n",
    "X = np.array(X)\r\n",
    "Y = np.array(Y)\r\n",
    "idx = np.argsort(X)\r\n",
    "X = X[idx]\r\n",
    "Y = Y[idx]\r\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fcb11bcf190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 考察局部匹配特征和不成对概率之间的关联。发现该特征效果不好，后舍弃。\r\n",
    "from MatchSub import CountMatch\r\n",
    "\r\n",
    "data_i=0\r\n",
    "seq = train_datas[data_i][1]\r\n",
    "cnt = CountMatch(seq, 7)\r\n",
    "prob = train_datas[data_i][3]\r\n",
    "st={}\r\n",
    "for c in cnt:\r\n",
    "    st[c]=[]\r\n",
    "for c, p in zip(cnt, prob):\r\n",
    "    st[c].append(p)\r\n",
    "x=[]\r\n",
    "y=[]\r\n",
    "for k, v in st.items():\r\n",
    "    x.append(k)\r\n",
    "    y.append(sum(v)/len(v))\r\n",
    "    # print(k, sum(v)/len(v))\r\n",
    "plt.scatter(x, y)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "# 训练数据填充长度\r\n",
    "TRAIN_LENGTH = 768\r\n",
    "# 测试数据填充长度\r\n",
    "PREDICT_LENGTH = 5120\r\n",
    "# 头部填充长度\r\n",
    "PRE_FILL = 128\r\n",
    "# 数据类型\r\n",
    "DTYPE = np.float32\r\n",
    "\r\n",
    "# 是否使用原始序列编码特征\r\n",
    "USE_SEQ = True\r\n",
    "# 是否使用结构序列编码特征\r\n",
    "USE_DOT = True\r\n",
    "# 是否使用foldc结构特征\r\n",
    "USE_FOLD_C = True\r\n",
    "# 是否使用contrafold结构特征\r\n",
    "USE_CONTRAFOLD = True\r\n",
    "# 不使用平均概率特征\r\n",
    "USE_MEAN_PROB = False\r\n",
    "# 不使用局部匹配特征\r\n",
    "MATCH_NEIGHBORS = []\r\n",
    "\r\n",
    "if USE_FOLD_C:\r\n",
    "    # 读取预处理的foldc结构序列\r\n",
    "    data = List2Dict(ReadFasta(FOLDC_FEATURE_FILE, with_structure=True))\r\n",
    "    fold_c_features = {}\r\n",
    "    for sid, val in data.items():\r\n",
    "        fold_c_features[sid] = val[2]\r\n",
    "\r\n",
    "if USE_CONTRAFOLD:\r\n",
    "    # 读取预处理的contrafold结构序列\r\n",
    "    contrafold_features = []\r\n",
    "    for f in CONTRAFOLD_FEATURE_FILES:\r\n",
    "        data = List2Dict(ReadFasta(f, with_structure=True))\r\n",
    "        feature = {}\r\n",
    "        for sid, val in data.items():\r\n",
    "            feature[sid]=val[2]\r\n",
    "        contrafold_features.append(feature)\r\n",
    "\r\n",
    "# 计算A、C、G、U的平均概率，未使用该特征\r\n",
    "PROB_DICT = {}\r\n",
    "for k, v in prob_dict.items():\r\n",
    "    PROB_DICT[k]=sum(v)/len(v)\r\n",
    "\r\n",
    "# 对序列进行one hot编码，编码字典为coder\r\n",
    "def Codec(seq, fill_length = TRAIN_LENGTH, pre_fill = PRE_FILL, coder={'A':0, 'C':1, 'G':2, 'U':3}):\r\n",
    "    l = len(seq)\r\n",
    "    feature = np.zeros([len(coder), fill_length], dtype=DTYPE)\r\n",
    "    for i in range(l):\r\n",
    "        feature[coder[seq[i]], pre_fill+i]=1.\r\n",
    "    return feature\r\n",
    "\r\n",
    "# 将序列填充到指定长度，序列头部填充指定长度的零\r\n",
    "def Fill(feature, fill_length = TRAIN_LENGTH, pre_fill = PRE_FILL):\r\n",
    "    if len(feature.shape)==1:\r\n",
    "        feature = feature.reshape([1, -1])\r\n",
    "    D = feature.shape[0]\r\n",
    "    feature = feature.reshape([D, -1])\r\n",
    "    L = feature.shape[1]\r\n",
    "    filled = np.zeros([D, fill_length], dtype=DTYPE)\r\n",
    "    filled[:, pre_fill:(pre_fill+L)] = feature\r\n",
    "    return filled\r\n",
    "\r\n",
    "# 将ACGU序列转换为对应的平均概率序列\r\n",
    "def MeanProbFeature(seq, fill_length = TRAIN_LENGTH, pre_fill = PRE_FILL, dt=PROB_DICT):\r\n",
    "    l = len(seq)\r\n",
    "    feature = np.zeros([1, fill_length], dtype=DTYPE)\r\n",
    "    for i in range(l):\r\n",
    "        feature[0, pre_fill+i]=dt[seq[i]]\r\n",
    "    return feature\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">id_1 (22, 768) 428 (768,) (768,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(data, fill_length = TRAIN_LENGTH, pre_fill = PRE_FILL):\r\n",
    "    ## 按预定义参数把RNA序列转换为特征序列。本方法用到的都是one hot编码的特征。\r\n",
    "    ## 返回值中的data[0]为序列名，feature为转换后的特征，l为原始序列长度，mask为填充的掩码，对训练集多返回一个prob为标签。\r\n",
    "    coder = {'A':0, 'C':1, 'G':2, 'U':3, '.':0, '(':1, ')':2}\r\n",
    "    l = len(data[1])\r\n",
    "    mask = np.zeros([fill_length], dtype=DTYPE)\r\n",
    "    mask[pre_fill:(l+pre_fill)]=1.\r\n",
    "    features = []\r\n",
    "    if USE_SEQ:\r\n",
    "        features.append(Codec(data[1], fill_length, pre_fill, coder={'A':0, 'C':1, 'G':2, 'U':3}))\r\n",
    "    if USE_DOT:\r\n",
    "        features.append(Codec(data[2], fill_length, pre_fill, coder={'.':0, '(':1, ')':2}))\r\n",
    "    if USE_FOLD_C:\r\n",
    "        features.append(Codec(fold_c_features[data[0]], fill_length, pre_fill, coder={'.':0, '(':1, ')':2}))\r\n",
    "    if USE_CONTRAFOLD:\r\n",
    "        for f in contrafold_features:\r\n",
    "            features.append(Codec(f[data[0]], fill_length, pre_fill, coder={'.':0, '(':1, ')':2}))\r\n",
    "    if USE_MEAN_PROB:\r\n",
    "        features.append(MeanProbFeature(data[1], fill_length, pre_fill))\r\n",
    "    for W in MATCH_NEIGHBORS:\r\n",
    "        features.append(Fill(CountMatch(data[1], W), fill_length, pre_fill))\r\n",
    "    feature = np.concatenate(features)\r\n",
    "    # feature = np.expand_dims(feature, axis=0)\r\n",
    "    if len(data)>3:\r\n",
    "        prob = np.zeros([fill_length], dtype=DTYPE)\r\n",
    "        prob[pre_fill:(l+pre_fill)] = np.array(data[3], dtype=DTYPE)\r\n",
    "        return (data[0], feature, l, mask, prob)\r\n",
    "    else:\r\n",
    "        return (data[0], feature, l, mask)\r\n",
    "def select_output(result_filled, l, pre_fill = PRE_FILL):\r\n",
    "    ## 提取结果中对应于输入的那部分，填充部分去掉。ed, l, pre_fill = PRE_FILL):\r\n",
    "    if len(result_filled.shape)>1:\r\n",
    "        result_filled = result_filled.reshape([-1])\r\n",
    "    return result_filled[pre_fill:(pre_fill+l)]\r\n",
    "\r\n",
    "## 对特征转换进行测试\r\n",
    "name, feature, l, mask, prob = preprocess(train_datas[0])\r\n",
    "INPUT_DEPTH = feature.shape[0]\r\n",
    "print(name, feature.shape, l, mask.shape, prob.shape)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4750/4750 [00:02<00:00, 2226.56it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 1053.12it/s]\n",
      "100%|██████████| 112/112 [00:00<00:00, 1099.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750 250 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 对训练集、验证集、测试集进行特征提取预处理。\r\n",
    "\r\n",
    "train_dataset = [preprocess(d, TRAIN_LENGTH) for d in tqdm(train_datas)]\r\n",
    "dev_dataset = [preprocess(d, PREDICT_LENGTH) for d in tqdm(dev_datas)]\r\n",
    "test_dataset = [preprocess(d, PREDICT_LENGTH) for d in tqdm(test_datas)]\r\n",
    "print(len(train_dataset), len(dev_dataset), len(test_dataset))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "## 对训练集进行重新划分，以避免验证集太少导致的过拟合。\r\n",
    "SPLIT_TRAIN = True\r\n",
    "DEV_PERCENT = 0.2\r\n",
    "\r\n",
    "if SPLIT_TRAIN:\r\n",
    "    all_dataset = train_dataset+[(d[0], d[1][:, :TRAIN_LENGTH], d[2], d[3][:TRAIN_LENGTH], d[4][:TRAIN_LENGTH]) for d in dev_dataset]\r\n",
    "    dev_cnt = int(DEV_PERCENT*len(all_dataset))\r\n",
    "    np.random.shuffle(all_dataset)\r\n",
    "    train_dataset = all_dataset[dev_cnt:]\r\n",
    "    dev_dataset = all_dataset[:dev_cnt]\r\n",
    "    # dev_dataset = [(d[0], d[1], d[2], d[3], d[4]) for d in dev_dataset]\r\n",
    "    print(len(train_dataset), len(dev_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import visualdl\r\n",
    "\r\n",
    "# 预测时加载哪个模型的参数\r\n",
    "USE_MODEL = 'best_model'\r\n",
    "# 结果保存文件夹\r\n",
    "OUTPUT_PATH = 'predict'\r\n",
    "# 输出时是否增加sigmoid层，A榜测试时发现不加效果更好。\r\n",
    "OUTPUT_WITH_SIGMOID = False\r\n",
    "\r\n",
    "# 使用BifpnModel，即后续的BifpnModel类\r\n",
    "MODEL_NAME = 'BifpnModel'\r\n",
    "\r\n",
    "# 训练轮数。我一般训练30-40轮就人工停止了。\r\n",
    "EPOCHS = 100\r\n",
    "BATCH_SIZE = 16\r\n",
    "LEARNING_RATE = 1e-4\r\n",
    "# 前5轮学习率为warm up，即从0线性增长到预定学习率。\r\n",
    "WARMUP_EPOCH = 5\r\n",
    "\r\n",
    "# 预测复现时设置为False，直接调用训练好的模型参数。设置为True时进入训练流程。\r\n",
    "TRAIN = False\r\n",
    "\r\n",
    "#################\r\n",
    "### SimpleCNN ###\r\n",
    "#################\r\n",
    "LAYERS = [4,4,4]\r\n",
    "KERNEL_SIZE = 11\r\n",
    "BASE_DEPTH = 32\r\n",
    "\r\n",
    "##################\r\n",
    "### BifpnModel ###\r\n",
    "##################\r\n",
    "\r\n",
    "# 扩张层的特征扩张倍数\r\n",
    "DEPTH_MULTIPLIER = 6\r\n",
    "\r\n",
    "# 网络结构设置\r\n",
    "BACKBONE=[\r\n",
    "    [('MBConv',4,7),],\r\n",
    "    [('MBConv',8,5),('MBConv',8,5),],\r\n",
    "    [('MBConv',16,5),('MBConv',16,5),],\r\n",
    "    [('MBConv',32,5),('MBConv',32,5),],\r\n",
    "    [('MBConv',48,5),('MBConv',48,5),],\r\n",
    "    [('MBConv',64,5),('MBConv',64,5),],\r\n",
    "]\r\n",
    "BIFPN_SETTING=[('Conv',8,5),('Conv',8,5),('Conv',8,5),('Conv',4,5),]\r\n",
    "UP_STAGE = ('Conv',4,5)\r\n",
    "BASE_CHANNELS=16\r\n",
    "DROPOUT_RATE=0.5\r\n",
    "\r\n",
    "###############\r\n",
    "### Predict ###\r\n",
    "###############\r\n",
    "\r\n",
    "# 是否对结果进行非线性变换，使结果更偏向于0和1。A榜测试时发现后处理效果不好。\r\n",
    "USE_POST_PROCESS = False\r\n",
    "\r\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 竞赛初期采用的一维卷积网络，仅用于验证一维卷积对本问题的适用性。\r\n",
    "class SimpleCNN(paddle.nn.Layer):\r\n",
    "    def __init__(self, layers = LAYERS, kernel_size = KERNEL_SIZE, base_depth = BASE_DEPTH):\r\n",
    "        super(SimpleCNN, self).__init__()\r\n",
    "        depths = [d*base_depth for d in layers]\r\n",
    "        pre_layer = [INPUT_DEPTH]+depths[:-1]\r\n",
    "        convs = [paddle.nn.Conv1D(pred, d, kernel_size, padding='SAME') for pred, d in zip(pre_layer, depths)]\r\n",
    "        # for layer_id, layer in enumerate(convs):\r\n",
    "        #     self.add_sublayer('convs_%d'%layer_id, layer)\r\n",
    "        self.out = paddle.nn.Conv1D(depths[-1], 1, 1, padding='SAME')\r\n",
    "        self.convs = paddle.nn.LayerList(convs)\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        x=inputs\r\n",
    "        for layer in self.convs:\r\n",
    "            x = layer(x)\r\n",
    "            x = paddle.nn.functional.relu(x)\r\n",
    "        x = self.out(x)\r\n",
    "        if OUTPUT_WITH_SIGMOID:\r\n",
    "            x = paddle.nn.functional.sigmoid(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 一些组建网络的基本模块\n",
    "\n",
    "def CheckList(param, cnt):\n",
    "\t'''\n",
    "\tif param is int, convert to list\n",
    "\t'''\n",
    "\tif '__len__' in dir(param):\n",
    "\t\tif len(param)!=cnt:\n",
    "\t\t\traise ValueError('parameter has wrong length. cnt=%d, len(param)=%d'%(cnt, len(param)))\n",
    "\telse:\n",
    "\t\tparam = [param]*cnt\n",
    "\treturn param\n",
    "def DownSampling(in_channels, out_channels, kernel_size):\n",
    "\treturn paddle.nn.Conv1D(in_channels, out_channels, kernel_size, stride=2, padding='SAME')\n",
    "def UpSampling(in_channels, out_channels):\n",
    "\treturn paddle.nn.Conv1DTranspose(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "def Activation():\n",
    "\treturn paddle.nn.Hardswish()\n",
    "def Conv(in_channels, out_channels, kernel_size, act=True, bias=True):\n",
    "\tif bias==True:\n",
    "\t\t# None means default\n",
    "\t\tbias = None\n",
    "\tconv_func = paddle.nn.Conv1D(in_channels, out_channels, kernel_size, padding='SAME', bias_attr=bias)\n",
    "\tif act:\n",
    "\t\tconv_func = paddle.nn.Sequential(\n",
    "\t\t\tconv_func,\n",
    "\t\t\tActivation()\n",
    "\t\t)\n",
    "\treturn conv_func\n",
    "def DepthConv(in_channels, out_channels, kernel_size, depth_multiplier=DEPTH_MULTIPLIER):\n",
    "\tmid_channels=depth_multiplier*in_channels\n",
    "\treturn paddle.nn.Sequential(\n",
    "\t\tConv(in_channels, mid_channels, 1, act=True, bias=True),\n",
    "\t\tpaddle.nn.Conv1D(mid_channels, mid_channels, kernel_size, padding='SAME', groups=mid_channels),\n",
    "\t\tActivation(),\n",
    "\t\tConv(mid_channels, out_channels, 1, act=False, bias=False)\n",
    "\t)\n",
    "class MBConv(paddle.nn.Layer):\n",
    "\tdef __init__(self, in_channels, out_channels, kernel_size):\n",
    "\t\tsuper(MBConv, self).__init__()\n",
    "\t\tself.bridge = (in_channels!=out_channels)\n",
    "\t\tself.conv = DepthConv(in_channels, out_channels, kernel_size)\n",
    "\t\tself.bn = paddle.nn.BatchNorm1D(num_features=out_channels)\n",
    "\t\tif self.bridge:\n",
    "\t\t\tself.conv_bridge = Conv(in_channels, out_channels, 1, False, False)\n",
    "\tdef forward(self, x):\n",
    "\t\ty = self.conv(x)\n",
    "\t\tif self.bridge:\n",
    "\t\t\tx = self.conv_bridge(x)\n",
    "\t\tx = paddle.add(x,y)\n",
    "\t\tx = self.bn(x)\n",
    "\t\treturn Activation()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_channels: [256, 512, 1024, 2048]\n",
      "input: [32, 22, 512]\n",
      "feature: [32, 256, 512]\n",
      "feature: [32, 512, 256]\n",
      "feature: [32, 1024, 128]\n",
      "feature: [32, 2048, 64]\n"
     ]
    }
   ],
   "source": [
    "class Backbone(paddle.nn.Layer):\n",
    "    '''按参数设置生成backbone网络，网络的输出是金字塔特征组'''\n",
    "    def __init__(self, input_channels, backbone_setting, base_channels, dropout_rate=0):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        # 用于串联层的临时变量\n",
    "        self._in_channel = input_channels\n",
    "        self.base_channels = base_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.feature_channels = [bs[-1][1]*base_channels for bs in backbone_setting]\n",
    "        self.layers = paddle.nn.LayerList([self.make_stage(bs, i==0) for i, bs in enumerate(backbone_setting)])\n",
    "        del self._in_channel\n",
    "\n",
    "    def forward(self, x):\n",
    "        #TODO:\n",
    "        _, f, _ = x.shape\n",
    "        if f!=self.input_channels:\n",
    "            raise ValueError('输入数据特征不匹配')\n",
    "        features = []\n",
    "        for layer_id, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            features.append(x)\n",
    "            if layer_id == len(self.layers)-1:\n",
    "                x = paddle.nn.MaxPool1D(2)(x)\n",
    "            if self.dropout_rate>0:\n",
    "                x = paddle.nn.Dropout(self.dropout_rate)(x)\n",
    "        return features\n",
    "    \n",
    "    def make_stage(self, stage_setting, first_one=False):\n",
    "        in_ch = self._in_channel\n",
    "        layers = []\n",
    "        if not first_one:\n",
    "            layers.append(paddle.nn.MaxPool1D(2))\n",
    "        for conv_func, fm, ks in stage_setting:\n",
    "            out_ch = fm*self.base_channels\n",
    "            layers.append(eval(conv_func)(in_ch, out_ch, ks))\n",
    "            in_ch = out_ch\n",
    "            if conv_func == 'Conv':\n",
    "                layers.append(paddle.nn.BatchNorm1D(num_features=in_ch))\n",
    "        self._in_channel = in_ch\n",
    "        return paddle.nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BifpnModule(paddle.nn.Layer):\n",
    "    '''对金字塔特征进行特征变换，结构参考EfficientDet中的BIFPN所设计。'''\n",
    "    def __init__(self, layer_depth, conv_func, in_channels, out_channels, kernel_size):\n",
    "        super(BifpnModule, self).__init__()\n",
    "        #TODO:\n",
    "        in_channels = CheckList(in_channels, layer_depth)\n",
    "        out_channels = CheckList(out_channels, layer_depth)\n",
    "        if isinstance(conv_func, str):\n",
    "            conv_func = eval(conv_func)\n",
    "        # print('Bifpn:', in_channels, '->', out_channels)\n",
    "        self.input_convs = paddle.nn.LayerList([conv_func(ich, och, kernel_size) for ich, och in zip(in_channels, out_channels)])\n",
    "        self.mid_convs = paddle.nn.LayerList([conv_func(ch, ch, kernel_size) for ch in out_channels[:-1]])\n",
    "        self.ups = paddle.nn.LayerList([UpSampling(ich, och) for ich,och in zip(out_channels[1:], out_channels[:-1])])\n",
    "        self.downs = paddle.nn.LayerList([DownSampling(ich, och, kernel_size) for ich,och in zip(out_channels[:-1], out_channels[1:])])\n",
    "        self.output_convs = paddle.nn.LayerList([conv_func(ch, ch, kernel_size) for ch in out_channels[1:]])\n",
    "\n",
    "    def forward(self, features):\n",
    "        #TODO:\n",
    "        N = len(features)\n",
    "        Pi = [conv(f) for conv, f in zip(self.input_convs, features)]\n",
    "        Ptd = []\n",
    "        Pu = [self.ups[N-2](Pi[-1])]\n",
    "        # print('use ups[%d]'%(N-2))\n",
    "        for i in range(-2, -N-1, -1):\n",
    "            x = paddle.add(Pu[-1], Pi[i])\n",
    "            x = self.mid_convs[N+i](x)\n",
    "            # print('use mid_convs[%d] and ups[%d]'%(N+i, N+i-1))\n",
    "            Ptd.append(x)\n",
    "            if N+i>0:\n",
    "                Pu.append(self.ups[N+i-1](x))\n",
    "        Po=[Ptd[-1]]\n",
    "        Ptd.pop()\n",
    "        for i in range(N-2):\n",
    "            # x = paddle.nn.MaxPool1D(2)(Po[-1])\n",
    "            x = self.downs[i](Po[-1])\n",
    "            x = paddle.add_n([x, Ptd[-1], Pi[i+1]])\n",
    "            Ptd.pop()\n",
    "            Po.append(self.output_convs[i](x))\n",
    "            # print('use output_convs[%d]'%(i))\n",
    "        x = paddle.add(self.downs[N-2](Po[-1]), Pi[-1])\n",
    "        Po.append(self.output_convs[N-2](x))\n",
    "        # print('use output_convs[%d]'%(N-1))\n",
    "        return Po\n",
    "# #TODO: test it\n",
    "# bifpn = BifpnModule(len(features), 'Conv', back.feature_channels, [128, 256, 512, 1024], 5)\n",
    "# # bifpn = BifpnModule(len(features), 'Conv', back.feature_channels, 256, 5)\n",
    "# features = bifpn(features)\n",
    "# for f in features:\n",
    "#     print('feature:', f.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UpStage(paddle.nn.Layer):\n",
    "    '''将变换后的特征逐层上采样，直到得出与输入长度一致的一维输出'''\n",
    "    def __init__(self, layer_depth, conv_func, in_channels, out_channels, kernel_size):\n",
    "        super(UpStage, self).__init__()\n",
    "        in_channels = CheckList(in_channels, layer_depth)\n",
    "        out_channels = CheckList(out_channels, layer_depth)\n",
    "        #TODO:\n",
    "        if isinstance(conv_func, str):\n",
    "            conv_func = eval(conv_func)\n",
    "        self.convs = paddle.nn.LayerList([conv_func(ich, och, kernel_size) for ich, och in zip(in_channels, out_channels)])\n",
    "        self.ups = paddle.nn.LayerList([UpSampling(ich, och) for ich,och in zip(out_channels[1:], out_channels[:-1])])\n",
    "        self.output_channels = out_channels[0]\n",
    "        # self.output = Conv(out_channels[0], 1, 1)\n",
    "\n",
    "    def forward(self, features):\n",
    "        #TODO:\n",
    "        N = len(features)\n",
    "        features = [conv(f) for conv, f in zip(self.convs, features)]\n",
    "        x = features[-1]\n",
    "        # print(x.shape)\n",
    "        for i in range(N-2, -1, -1):\n",
    "            # print('i=%d'%i)\n",
    "            x = paddle.add_n([features[i], self.ups[i](x)])\n",
    "        # x = self.output(x)\n",
    "        return x\n",
    "# #TODO: test it\n",
    "# upstage = UpStage(4, 'MBConv', [128, 256, 512, 1024], [64, 128, 256, 512], 5)\n",
    "# out = upstage(features)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BifpnModel(paddle.nn.Layer):\n",
    "    '''将backbone网络、bifpn网络、上采样网络组合成一个完整的端到端模型。'''\n",
    "    def __init__(self, \n",
    "                 input_channels = INPUT_DEPTH,\n",
    "                 backbone_setting = BACKBONE, \n",
    "                 bifpn_setting = BIFPN_SETTING, \n",
    "                 up_stage = UP_STAGE,\n",
    "                #  depth_multiplier = DEPTH_MULTIPLIER,\n",
    "                 base_channels = BASE_CHANNELS,\n",
    "                 dropout_rate = DROPOUT_RATE):\n",
    "        super(BifpnModel, self).__init__()\n",
    "        layer_depth = len(backbone_setting)\n",
    "        self.backbone = Backbone(input_channels, backbone_setting, base_channels, dropout_rate)\n",
    "        def multiply(fm, base):\n",
    "            if '__len__' in dir(fm):\n",
    "                fm = [f*base for f in fm]\n",
    "            else:\n",
    "                fm *= base\n",
    "            return fm\n",
    "        in_filters = [self.backbone.feature_channels]+[CheckList(multiply(fm,base_channels),layer_depth) for _,fm,_ in bifpn_setting]\n",
    "        out_filters = in_filters[-1]\n",
    "        in_filters = in_filters[:-1]\n",
    "        self.bifpns = paddle.nn.Sequential(*[BifpnModule(layer_depth, conv_func, in_filters[bifpn_id], multiply(fm,base_channels), ks) for bifpn_id, (conv_func, fm, ks) in enumerate(bifpn_setting)])\n",
    "        up_conv, up_fm, up_ks = up_stage\n",
    "        self.ups = UpStage(layer_depth, up_conv, out_filters, multiply(up_fm,base_channels), up_ks)\n",
    "        self.out = paddle.nn.Conv1D(self.ups.output_channels, 1, 1, padding='SAME')\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        fps = self.backbone(inputs)\n",
    "        fps = self.bifpns(fps)\n",
    "        x = self.ups(fps)\n",
    "        x = self.out(x)\n",
    "        if OUTPUT_WITH_SIGMOID:\n",
    "            x = paddle.nn.functional.sigmoid(x)\n",
    "        return x\n",
    "# model = BifpnModel()\n",
    "# x = paddle.zeros([32, INPUT_DEPTH, 512])\n",
    "# out = model(x)\n",
    "# print(out.shape)\n",
    "# paddle.summary(model, input_size=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''竞赛初期测试时采用的简单lstm网络'''\r\n",
    "class SimpleLSTM(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(SimpleLSTM, self).__init__()\r\n",
    "        depth = 64\r\n",
    "        self.rnn_0 = paddle.nn.BiRNN(paddle.nn.LSTMCell(INPUT_DEPTH, depth), paddle.nn.LSTMCell(INPUT_DEPTH, depth))\r\n",
    "        # self.rnn_1 = paddle.nn.BiRNN(paddle.nn.LSTMCell(depth*2, depth), paddle.nn.LSTMCell(depth*2, depth))\r\n",
    "        # self.rnn_2 = paddle.nn.BiRNN(paddle.nn.LSTMCell(depth*2, depth), paddle.nn.LSTMCell(depth*2, depth))\r\n",
    "        self.out = paddle.nn.Linear(depth*2, 1)\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = paddle.transpose(inputs, [0, 2, 1])\r\n",
    "        x, _ = self.rnn_0(x)\r\n",
    "        # x, _ = self.rnn_1(x)\r\n",
    "        # x, _ = self.rnn_2(x)\r\n",
    "        x = self.out(x)\r\n",
    "        if OUTPUT_WITH_SIGMOID:\r\n",
    "            x = paddle.nn.functional.sigmoid(x)\r\n",
    "        return paddle.transpose(x, [0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(model, dataset, batch_size=BATCH_SIZE, fill_length=PREDICT_LENGTH):\r\n",
    "    '''逐batch预测结果，并将结果还原到原始序列长度'''\r\n",
    "    X = np.zeros([len(dataset), INPUT_DEPTH, fill_length], dtype=DTYPE)\r\n",
    "    Yp = np.zeros([len(dataset), 1, fill_length], dtype=DTYPE)\r\n",
    "    for i, data in enumerate(dataset):\r\n",
    "        X[i]=data[1]\r\n",
    "    model.eval()\r\n",
    "    for i in range(0, len(dataset), batch_size):\r\n",
    "        batch_X = paddle.to_tensor(X[i:(i+batch_size)])\r\n",
    "        batch_Yp = model(batch_X).numpy().clip(0, 1)\r\n",
    "        Yp[i:(i+batch_size)] = batch_Yp\r\n",
    "    return [select_output(yp, data[2]) for yp, data in zip(Yp, dataset)]\r\n",
    "\r\n",
    "def train(model, epochs = EPOCHS, batch_size=BATCH_SIZE, shuffle=True):\r\n",
    "    '''\r\n",
    "    训练主函数，采用VisualDL可视化训练过程。\r\n",
    "    每10 epochs或得到最好结果时，保存一次模型参数。\r\n",
    "    '''\r\n",
    "    print('start train.')\r\n",
    "    start_time = time.time()\r\n",
    "    batch_per_epoch = len(train_dataset)//batch_size\r\n",
    "    iters_all = epochs*batch_per_epoch\r\n",
    "    lr_scheduler = paddle.optimizer.lr.PolynomialDecay(LEARNING_RATE, power=0.9, decay_steps=iters_all, end_lr=0)\r\n",
    "    lr_warmup = paddle.optimizer.lr.LinearWarmup(lr_scheduler, batch_per_epoch*WARMUP_EPOCH, 0, LEARNING_RATE)\r\n",
    "    opt = paddle.optimizer.Adam(learning_rate=lr_warmup, parameters=model.parameters())\r\n",
    "    # loss_fn = lambda Y, Yp, mask:paddle.nn.SmoothL1Loss()(Y*mask, Yp*mask)\r\n",
    "    loss_fn = lambda Y, Yp, mask:paddle.sqrt(paddle.sum(paddle.square(Y-Yp)*mask)/paddle.sum(mask))\r\n",
    "    best_rmsd = 1e10\r\n",
    "    best_epoch = 0\r\n",
    "    vdl_path = 'Models/vdl_log/'\r\n",
    "    if os.path.exists(vdl_path):\r\n",
    "        os.system('rm -rf %s'%vdl_path)\r\n",
    "    vdl_writer = visualdl.LogWriter(vdl_path)\r\n",
    "    iter = 0\r\n",
    "    for epoch in range(epochs):\r\n",
    "        if shuffle:\r\n",
    "            np.random.shuffle(train_dataset)\r\n",
    "        model.train()\r\n",
    "        batch_X = np.zeros([batch_size, INPUT_DEPTH, TRAIN_LENGTH], dtype=DTYPE)\r\n",
    "        batch_Y = np.zeros([batch_size, 1, TRAIN_LENGTH], dtype=DTYPE)\r\n",
    "        batch_mask = np.zeros([batch_size, 1, TRAIN_LENGTH], dtype=DTYPE)\r\n",
    "        bs_i = 0\r\n",
    "        bs_cnt = 0\r\n",
    "        sys.stdout.flush()\r\n",
    "        time.sleep(1)\r\n",
    "        for data in tqdm(train_dataset):\r\n",
    "            batch_X[bs_i] = data[1]\r\n",
    "            batch_Y[bs_i, 0] = data[4]\r\n",
    "            batch_mask[bs_i, 0] = data[3]\r\n",
    "            bs_i+=1\r\n",
    "            if bs_i == batch_size:\r\n",
    "                iter += 1\r\n",
    "                X = paddle.to_tensor(batch_X)\r\n",
    "                Y = paddle.to_tensor(batch_Y)\r\n",
    "                mask = paddle.to_tensor(batch_mask)\r\n",
    "                Yp = model(X)\r\n",
    "                loss = loss_fn(Y, Yp, mask)\r\n",
    "                # loss_scalar = min(1., loss.numpy()[0])\r\n",
    "                loss_scalar = loss.numpy()[0]\r\n",
    "                if loss_scalar>1:\r\n",
    "                    loss_scalar = 1+(loss_scalar-1)/1000\r\n",
    "                vdl_writer.add_scalar('loss', loss_scalar, iter)\r\n",
    "                vdl_writer.add_scalar('learning_rate', opt.get_lr(), iter)\r\n",
    "                loss.backward()\r\n",
    "                opt.step()\r\n",
    "                if isinstance(opt._learning_rate,\r\n",
    "                            paddle.optimizer.lr.LRScheduler):\r\n",
    "                    opt._learning_rate.step()\r\n",
    "                opt.clear_grad()\r\n",
    "                bs_i = 0\r\n",
    "                bs_cnt+=1\r\n",
    "        Yp = predict(model, dev_dataset, fill_length = TRAIN_LENGTH)\r\n",
    "        rmsd = 0\r\n",
    "        for data, yp in zip(dev_dataset, Yp):\r\n",
    "            y=select_output(data[4], data[2])\r\n",
    "            rmsd += np.sqrt(np.mean((y-yp)*(y-yp)))\r\n",
    "        rmsd /= len(dev_dataset)\r\n",
    "        vdl_writer.add_scalar('valid_rmsd', rmsd, epoch)\r\n",
    "        if (epoch+1)%10==0:\r\n",
    "            save_path = 'Models/epoch_%d/'%(epoch+1)\r\n",
    "            if os.path.exists(save_path):\r\n",
    "                os.system('rm -rf %s'%save_path)\r\n",
    "            paddle.save(model.state_dict(), save_path+'model.pdparams')\r\n",
    "            # paddle.save(opt.state_dict(), save_path+'opt.pdopt')\r\n",
    "            print('Save to', save_path)\r\n",
    "        if rmsd<best_rmsd:\r\n",
    "            save_path = 'Models/best_model/'\r\n",
    "            if os.path.exists(save_path):\r\n",
    "                os.system('rm -rf %s'%save_path)\r\n",
    "            paddle.save(model.state_dict(), save_path+'model.pdparams')\r\n",
    "            # paddle.save(opt.state_dict(), save_path+'opt.pdopt')\r\n",
    "            print('Save to', save_path, 'with rmsd =', rmsd)\r\n",
    "            best_rmsd = rmsd\r\n",
    "            best_epoch = epoch+1\r\n",
    "        print('epoch_%d, %04.0fs: rmsd of valid is %g, best rmsd is %g at epoch_%d'%(epoch+1, time.time()-start_time, rmsd, best_rmsd, best_epoch))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   Layer (type)                                              Input Shape                                                                                   Output Shape                                              Param #    \n",
      "==================================================================================================================================================================================================================================\n",
      "     Conv1D-1                                              [[16, 22, 768]]                                                                                [16, 132, 768]                                              3,036     \n",
      "   Hardswish-1                                            [[16, 132, 768]]                                                                                [16, 132, 768]                                                0       \n",
      "     Conv1D-2                                             [[16, 132, 768]]                                                                                [16, 132, 768]                                              1,056     \n",
      "   Hardswish-2                                            [[16, 132, 768]]                                                                                [16, 132, 768]                                                0       \n",
      "     Conv1D-3                                             [[16, 132, 768]]                                                                                 [16, 64, 768]                                              8,448     \n",
      "     Conv1D-4                                              [[16, 22, 768]]                                                                                 [16, 64, 768]                                              1,408     \n",
      "  BatchNorm1D-1                                            [[16, 64, 768]]                                                                                 [16, 64, 768]                                               256      \n",
      "     MBConv-1                                              [[16, 22, 768]]                                                                                 [16, 64, 768]                                                0       \n",
      "   MaxPool1D-1                                             [[16, 64, 768]]                                                                                 [16, 64, 384]                                                0       \n",
      "     Conv1D-5                                              [[16, 64, 384]]                                                                                [16, 384, 384]                                             24,960     \n",
      "   Hardswish-3                                            [[16, 384, 384]]                                                                                [16, 384, 384]                                                0       \n",
      "     Conv1D-6                                             [[16, 384, 384]]                                                                                [16, 384, 384]                                              2,304     \n",
      "   Hardswish-4                                            [[16, 384, 384]]                                                                                [16, 384, 384]                                                0       \n",
      "     Conv1D-7                                             [[16, 384, 384]]                                                                                [16, 128, 384]                                             49,152     \n",
      "     Conv1D-8                                              [[16, 64, 384]]                                                                                [16, 128, 384]                                              8,192     \n",
      "  BatchNorm1D-2                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                               512      \n",
      "     MBConv-2                                              [[16, 64, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "     Conv1D-9                                             [[16, 128, 384]]                                                                                [16, 768, 384]                                             99,072     \n",
      "   Hardswish-5                                            [[16, 768, 384]]                                                                                [16, 768, 384]                                                0       \n",
      "    Conv1D-10                                             [[16, 768, 384]]                                                                                [16, 768, 384]                                              4,608     \n",
      "   Hardswish-6                                            [[16, 768, 384]]                                                                                [16, 768, 384]                                                0       \n",
      "    Conv1D-11                                             [[16, 768, 384]]                                                                                [16, 128, 384]                                             98,304     \n",
      "  BatchNorm1D-3                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                               512      \n",
      "     MBConv-3                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "   MaxPool1D-2                                            [[16, 128, 384]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-12                                             [[16, 128, 192]]                                                                                [16, 768, 192]                                             99,072     \n",
      "   Hardswish-7                                            [[16, 768, 192]]                                                                                [16, 768, 192]                                                0       \n",
      "    Conv1D-13                                             [[16, 768, 192]]                                                                                [16, 768, 192]                                              4,608     \n",
      "   Hardswish-8                                            [[16, 768, 192]]                                                                                [16, 768, 192]                                                0       \n",
      "    Conv1D-14                                             [[16, 768, 192]]                                                                                [16, 256, 192]                                             196,608    \n",
      "    Conv1D-15                                             [[16, 128, 192]]                                                                                [16, 256, 192]                                             32,768     \n",
      "  BatchNorm1D-4                                           [[16, 256, 192]]                                                                                [16, 256, 192]                                              1,024     \n",
      "     MBConv-4                                             [[16, 128, 192]]                                                                                [16, 256, 192]                                                0       \n",
      "    Conv1D-16                                             [[16, 256, 192]]                                                                                [16, 1536, 192]                                            394,752    \n",
      "   Hardswish-9                                            [[16, 1536, 192]]                                                                               [16, 1536, 192]                                               0       \n",
      "    Conv1D-17                                             [[16, 1536, 192]]                                                                               [16, 1536, 192]                                             9,216     \n",
      "   Hardswish-10                                           [[16, 1536, 192]]                                                                               [16, 1536, 192]                                               0       \n",
      "    Conv1D-18                                             [[16, 1536, 192]]                                                                               [16, 256, 192]                                             393,216    \n",
      "  BatchNorm1D-5                                           [[16, 256, 192]]                                                                                [16, 256, 192]                                              1,024     \n",
      "     MBConv-5                                             [[16, 256, 192]]                                                                                [16, 256, 192]                                                0       \n",
      "   MaxPool1D-3                                            [[16, 256, 192]]                                                                                 [16, 256, 96]                                                0       \n",
      "    Conv1D-19                                              [[16, 256, 96]]                                                                                [16, 1536, 96]                                             394,752    \n",
      "   Hardswish-11                                           [[16, 1536, 96]]                                                                                [16, 1536, 96]                                                0       \n",
      "    Conv1D-20                                             [[16, 1536, 96]]                                                                                [16, 1536, 96]                                              9,216     \n",
      "   Hardswish-12                                           [[16, 1536, 96]]                                                                                [16, 1536, 96]                                                0       \n",
      "    Conv1D-21                                             [[16, 1536, 96]]                                                                                 [16, 512, 96]                                             786,432    \n",
      "    Conv1D-22                                              [[16, 256, 96]]                                                                                 [16, 512, 96]                                             131,072    \n",
      "  BatchNorm1D-6                                            [[16, 512, 96]]                                                                                 [16, 512, 96]                                              2,048     \n",
      "     MBConv-6                                              [[16, 256, 96]]                                                                                 [16, 512, 96]                                                0       \n",
      "    Conv1D-23                                              [[16, 512, 96]]                                                                                [16, 3072, 96]                                            1,575,936   \n",
      "   Hardswish-13                                           [[16, 3072, 96]]                                                                                [16, 3072, 96]                                                0       \n",
      "    Conv1D-24                                             [[16, 3072, 96]]                                                                                [16, 3072, 96]                                             18,432     \n",
      "   Hardswish-14                                           [[16, 3072, 96]]                                                                                [16, 3072, 96]                                                0       \n",
      "    Conv1D-25                                             [[16, 3072, 96]]                                                                                 [16, 512, 96]                                            1,572,864   \n",
      "  BatchNorm1D-7                                            [[16, 512, 96]]                                                                                 [16, 512, 96]                                              2,048     \n",
      "     MBConv-7                                              [[16, 512, 96]]                                                                                 [16, 512, 96]                                                0       \n",
      "   MaxPool1D-4                                             [[16, 512, 96]]                                                                                 [16, 512, 48]                                                0       \n",
      "    Conv1D-26                                              [[16, 512, 48]]                                                                                [16, 3072, 48]                                            1,575,936   \n",
      "   Hardswish-15                                           [[16, 3072, 48]]                                                                                [16, 3072, 48]                                                0       \n",
      "    Conv1D-27                                             [[16, 3072, 48]]                                                                                [16, 3072, 48]                                             18,432     \n",
      "   Hardswish-16                                           [[16, 3072, 48]]                                                                                [16, 3072, 48]                                                0       \n",
      "    Conv1D-28                                             [[16, 3072, 48]]                                                                                 [16, 768, 48]                                            2,359,296   \n",
      "    Conv1D-29                                              [[16, 512, 48]]                                                                                 [16, 768, 48]                                             393,216    \n",
      "  BatchNorm1D-8                                            [[16, 768, 48]]                                                                                 [16, 768, 48]                                              3,072     \n",
      "     MBConv-8                                              [[16, 512, 48]]                                                                                 [16, 768, 48]                                                0       \n",
      "    Conv1D-30                                              [[16, 768, 48]]                                                                                [16, 4608, 48]                                            3,543,552   \n",
      "   Hardswish-17                                           [[16, 4608, 48]]                                                                                [16, 4608, 48]                                                0       \n",
      "    Conv1D-31                                             [[16, 4608, 48]]                                                                                [16, 4608, 48]                                             27,648     \n",
      "   Hardswish-18                                           [[16, 4608, 48]]                                                                                [16, 4608, 48]                                                0       \n",
      "    Conv1D-32                                             [[16, 4608, 48]]                                                                                 [16, 768, 48]                                            3,538,944   \n",
      "  BatchNorm1D-9                                            [[16, 768, 48]]                                                                                 [16, 768, 48]                                              3,072     \n",
      "     MBConv-9                                              [[16, 768, 48]]                                                                                 [16, 768, 48]                                                0       \n",
      "   MaxPool1D-5                                             [[16, 768, 48]]                                                                                 [16, 768, 24]                                                0       \n",
      "    Conv1D-33                                              [[16, 768, 24]]                                                                                [16, 4608, 24]                                            3,543,552   \n",
      "   Hardswish-19                                           [[16, 4608, 24]]                                                                                [16, 4608, 24]                                                0       \n",
      "    Conv1D-34                                             [[16, 4608, 24]]                                                                                [16, 4608, 24]                                             27,648     \n",
      "   Hardswish-20                                           [[16, 4608, 24]]                                                                                [16, 4608, 24]                                                0       \n",
      "    Conv1D-35                                             [[16, 4608, 24]]                                                                                [16, 1024, 24]                                            4,718,592   \n",
      "    Conv1D-36                                              [[16, 768, 24]]                                                                                [16, 1024, 24]                                             786,432    \n",
      "  BatchNorm1D-10                                          [[16, 1024, 24]]                                                                                [16, 1024, 24]                                              4,096     \n",
      "    MBConv-10                                              [[16, 768, 24]]                                                                                [16, 1024, 24]                                                0       \n",
      "    Conv1D-37                                             [[16, 1024, 24]]                                                                                [16, 6144, 24]                                            6,297,600   \n",
      "   Hardswish-21                                           [[16, 6144, 24]]                                                                                [16, 6144, 24]                                                0       \n",
      "    Conv1D-38                                             [[16, 6144, 24]]                                                                                [16, 6144, 24]                                             36,864     \n",
      "   Hardswish-22                                           [[16, 6144, 24]]                                                                                [16, 6144, 24]                                                0       \n",
      "    Conv1D-39                                             [[16, 6144, 24]]                                                                                [16, 1024, 24]                                            6,291,456   \n",
      "  BatchNorm1D-11                                          [[16, 1024, 24]]                                                                                [16, 1024, 24]                                              4,096     \n",
      "    MBConv-11                                             [[16, 1024, 24]]                                                                                [16, 1024, 24]                                                0       \n",
      "    Backbone-1                                             [[16, 22, 768]]                                         [[16, 64, 768], [16, 128, 384], [16, 256, 192], [16, 512, 96], [16, 768, 48], [16, 1024, 24]]        0       \n",
      "    Conv1D-40                                              [[16, 64, 768]]                                                                                [16, 128, 768]                                             41,088     \n",
      "   Hardswish-23                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-41                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-24                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-42                                             [[16, 256, 192]]                                                                                [16, 128, 192]                                             163,968    \n",
      "   Hardswish-25                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-43                                              [[16, 512, 96]]                                                                                 [16, 128, 96]                                             327,808    \n",
      "   Hardswish-26                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-44                                              [[16, 768, 48]]                                                                                 [16, 128, 48]                                             491,648    \n",
      "   Hardswish-27                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-45                                             [[16, 1024, 24]]                                                                                 [16, 128, 24]                                             655,488    \n",
      "   Hardswish-28                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "Conv1DTranspose-5                                          [[16, 128, 24]]                                                                                 [16, 128, 48]                                             65,664     \n",
      "    Conv1D-50                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-33                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "Conv1DTranspose-4                                          [[16, 128, 48]]                                                                                 [16, 128, 96]                                             65,664     \n",
      "    Conv1D-49                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-32                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "Conv1DTranspose-3                                          [[16, 128, 96]]                                                                                [16, 128, 192]                                             65,664     \n",
      "    Conv1D-48                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-31                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "Conv1DTranspose-2                                         [[16, 128, 192]]                                                                                [16, 128, 384]                                             65,664     \n",
      "    Conv1D-47                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-30                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "Conv1DTranspose-1                                         [[16, 128, 384]]                                                                                [16, 128, 768]                                             65,664     \n",
      "    Conv1D-46                                             [[16, 128, 768]]                                                                                [16, 128, 768]                                             82,048     \n",
      "   Hardswish-29                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-51                                             [[16, 128, 768]]                                                                                [16, 128, 384]                                             82,048     \n",
      "    Conv1D-56                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-34                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-52                                             [[16, 128, 384]]                                                                                [16, 128, 192]                                             82,048     \n",
      "    Conv1D-57                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-35                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-53                                             [[16, 128, 192]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "    Conv1D-58                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-36                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-54                                              [[16, 128, 96]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "    Conv1D-59                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-37                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-55                                              [[16, 128, 48]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "    Conv1D-60                                              [[16, 128, 24]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "   Hardswish-38                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "  BifpnModule-1    [[[16, 64, 768], [16, 128, 384], [16, 256, 192], [16, 512, 96], [16, 768, 48], [16, 1024, 24]]] [[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]        0       \n",
      "    Conv1D-61                                             [[16, 128, 768]]                                                                                [16, 128, 768]                                             82,048     \n",
      "   Hardswish-39                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-62                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-40                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-63                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-41                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-64                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-42                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-65                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-43                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-66                                              [[16, 128, 24]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "   Hardswish-44                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "Conv1DTranspose-10                                         [[16, 128, 24]]                                                                                 [16, 128, 48]                                             65,664     \n",
      "    Conv1D-71                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-49                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "Conv1DTranspose-9                                          [[16, 128, 48]]                                                                                 [16, 128, 96]                                             65,664     \n",
      "    Conv1D-70                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-48                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "Conv1DTranspose-8                                          [[16, 128, 96]]                                                                                [16, 128, 192]                                             65,664     \n",
      "    Conv1D-69                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-47                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "Conv1DTranspose-7                                         [[16, 128, 192]]                                                                                [16, 128, 384]                                             65,664     \n",
      "    Conv1D-68                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-46                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "Conv1DTranspose-6                                         [[16, 128, 384]]                                                                                [16, 128, 768]                                             65,664     \n",
      "    Conv1D-67                                             [[16, 128, 768]]                                                                                [16, 128, 768]                                             82,048     \n",
      "   Hardswish-45                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-72                                             [[16, 128, 768]]                                                                                [16, 128, 384]                                             82,048     \n",
      "    Conv1D-77                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-50                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-73                                             [[16, 128, 384]]                                                                                [16, 128, 192]                                             82,048     \n",
      "    Conv1D-78                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-51                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-74                                             [[16, 128, 192]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "    Conv1D-79                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-52                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-75                                              [[16, 128, 96]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "    Conv1D-80                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-53                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-76                                              [[16, 128, 48]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "    Conv1D-81                                              [[16, 128, 24]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "   Hardswish-54                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "  BifpnModule-2    [[[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]] [[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]        0       \n",
      "    Conv1D-82                                             [[16, 128, 768]]                                                                                [16, 128, 768]                                             82,048     \n",
      "   Hardswish-55                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-83                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-56                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-84                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-57                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-85                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-58                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-86                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-59                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-87                                              [[16, 128, 24]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "   Hardswish-60                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "Conv1DTranspose-15                                         [[16, 128, 24]]                                                                                 [16, 128, 48]                                             65,664     \n",
      "    Conv1D-92                                              [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-65                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "Conv1DTranspose-14                                         [[16, 128, 48]]                                                                                 [16, 128, 96]                                             65,664     \n",
      "    Conv1D-91                                              [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-64                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "Conv1DTranspose-13                                         [[16, 128, 96]]                                                                                [16, 128, 192]                                             65,664     \n",
      "    Conv1D-90                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-63                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "Conv1DTranspose-12                                        [[16, 128, 192]]                                                                                [16, 128, 384]                                             65,664     \n",
      "    Conv1D-89                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-62                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "Conv1DTranspose-11                                        [[16, 128, 384]]                                                                                [16, 128, 768]                                             65,664     \n",
      "    Conv1D-88                                             [[16, 128, 768]]                                                                                [16, 128, 768]                                             82,048     \n",
      "   Hardswish-61                                           [[16, 128, 768]]                                                                                [16, 128, 768]                                                0       \n",
      "    Conv1D-93                                             [[16, 128, 768]]                                                                                [16, 128, 384]                                             82,048     \n",
      "    Conv1D-98                                             [[16, 128, 384]]                                                                                [16, 128, 384]                                             82,048     \n",
      "   Hardswish-66                                           [[16, 128, 384]]                                                                                [16, 128, 384]                                                0       \n",
      "    Conv1D-94                                             [[16, 128, 384]]                                                                                [16, 128, 192]                                             82,048     \n",
      "    Conv1D-99                                             [[16, 128, 192]]                                                                                [16, 128, 192]                                             82,048     \n",
      "   Hardswish-67                                           [[16, 128, 192]]                                                                                [16, 128, 192]                                                0       \n",
      "    Conv1D-95                                             [[16, 128, 192]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "    Conv1D-100                                             [[16, 128, 96]]                                                                                 [16, 128, 96]                                             82,048     \n",
      "   Hardswish-68                                            [[16, 128, 96]]                                                                                 [16, 128, 96]                                                0       \n",
      "    Conv1D-96                                              [[16, 128, 96]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "    Conv1D-101                                             [[16, 128, 48]]                                                                                 [16, 128, 48]                                             82,048     \n",
      "   Hardswish-69                                            [[16, 128, 48]]                                                                                 [16, 128, 48]                                                0       \n",
      "    Conv1D-97                                              [[16, 128, 48]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "    Conv1D-102                                             [[16, 128, 24]]                                                                                 [16, 128, 24]                                             82,048     \n",
      "   Hardswish-70                                            [[16, 128, 24]]                                                                                 [16, 128, 24]                                                0       \n",
      "  BifpnModule-3    [[[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]] [[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]        0       \n",
      "    Conv1D-103                                            [[16, 128, 768]]                                                                                 [16, 64, 768]                                             41,024     \n",
      "   Hardswish-71                                            [[16, 64, 768]]                                                                                 [16, 64, 768]                                                0       \n",
      "    Conv1D-104                                            [[16, 128, 384]]                                                                                 [16, 64, 384]                                             41,024     \n",
      "   Hardswish-72                                            [[16, 64, 384]]                                                                                 [16, 64, 384]                                                0       \n",
      "    Conv1D-105                                            [[16, 128, 192]]                                                                                 [16, 64, 192]                                             41,024     \n",
      "   Hardswish-73                                            [[16, 64, 192]]                                                                                 [16, 64, 192]                                                0       \n",
      "    Conv1D-106                                             [[16, 128, 96]]                                                                                 [16, 64, 96]                                              41,024     \n",
      "   Hardswish-74                                            [[16, 64, 96]]                                                                                  [16, 64, 96]                                                 0       \n",
      "    Conv1D-107                                             [[16, 128, 48]]                                                                                 [16, 64, 48]                                              41,024     \n",
      "   Hardswish-75                                            [[16, 64, 48]]                                                                                  [16, 64, 48]                                                 0       \n",
      "    Conv1D-108                                             [[16, 128, 24]]                                                                                 [16, 64, 24]                                              41,024     \n",
      "   Hardswish-76                                            [[16, 64, 24]]                                                                                  [16, 64, 24]                                                 0       \n",
      "Conv1DTranspose-20                                         [[16, 64, 24]]                                                                                  [16, 64, 48]                                              16,448     \n",
      "    Conv1D-113                                             [[16, 64, 48]]                                                                                  [16, 64, 48]                                              20,544     \n",
      "   Hardswish-81                                            [[16, 64, 48]]                                                                                  [16, 64, 48]                                                 0       \n",
      "Conv1DTranspose-19                                         [[16, 64, 48]]                                                                                  [16, 64, 96]                                              16,448     \n",
      "    Conv1D-112                                             [[16, 64, 96]]                                                                                  [16, 64, 96]                                              20,544     \n",
      "   Hardswish-80                                            [[16, 64, 96]]                                                                                  [16, 64, 96]                                                 0       \n",
      "Conv1DTranspose-18                                         [[16, 64, 96]]                                                                                  [16, 64, 192]                                             16,448     \n",
      "    Conv1D-111                                             [[16, 64, 192]]                                                                                 [16, 64, 192]                                             20,544     \n",
      "   Hardswish-79                                            [[16, 64, 192]]                                                                                 [16, 64, 192]                                                0       \n",
      "Conv1DTranspose-17                                         [[16, 64, 192]]                                                                                 [16, 64, 384]                                             16,448     \n",
      "    Conv1D-110                                             [[16, 64, 384]]                                                                                 [16, 64, 384]                                             20,544     \n",
      "   Hardswish-78                                            [[16, 64, 384]]                                                                                 [16, 64, 384]                                                0       \n",
      "Conv1DTranspose-16                                         [[16, 64, 384]]                                                                                 [16, 64, 768]                                             16,448     \n",
      "    Conv1D-109                                             [[16, 64, 768]]                                                                                 [16, 64, 768]                                             20,544     \n",
      "   Hardswish-77                                            [[16, 64, 768]]                                                                                 [16, 64, 768]                                                0       \n",
      "    Conv1D-114                                             [[16, 64, 768]]                                                                                 [16, 64, 384]                                             20,544     \n",
      "    Conv1D-119                                             [[16, 64, 384]]                                                                                 [16, 64, 384]                                             20,544     \n",
      "   Hardswish-82                                            [[16, 64, 384]]                                                                                 [16, 64, 384]                                                0       \n",
      "    Conv1D-115                                             [[16, 64, 384]]                                                                                 [16, 64, 192]                                             20,544     \n",
      "    Conv1D-120                                             [[16, 64, 192]]                                                                                 [16, 64, 192]                                             20,544     \n",
      "   Hardswish-83                                            [[16, 64, 192]]                                                                                 [16, 64, 192]                                                0       \n",
      "    Conv1D-116                                             [[16, 64, 192]]                                                                                 [16, 64, 96]                                              20,544     \n",
      "    Conv1D-121                                             [[16, 64, 96]]                                                                                  [16, 64, 96]                                              20,544     \n",
      "   Hardswish-84                                            [[16, 64, 96]]                                                                                  [16, 64, 96]                                                 0       \n",
      "    Conv1D-117                                             [[16, 64, 96]]                                                                                  [16, 64, 48]                                              20,544     \n",
      "    Conv1D-122                                             [[16, 64, 48]]                                                                                  [16, 64, 48]                                              20,544     \n",
      "   Hardswish-85                                            [[16, 64, 48]]                                                                                  [16, 64, 48]                                                 0       \n",
      "    Conv1D-118                                             [[16, 64, 48]]                                                                                  [16, 64, 24]                                              20,544     \n",
      "    Conv1D-123                                             [[16, 64, 24]]                                                                                  [16, 64, 24]                                              20,544     \n",
      "   Hardswish-86                                            [[16, 64, 24]]                                                                                  [16, 64, 24]                                                 0       \n",
      "  BifpnModule-4    [[[16, 128, 768], [16, 128, 384], [16, 128, 192], [16, 128, 96], [16, 128, 48], [16, 128, 24]]]    [[16, 64, 768], [16, 64, 384], [16, 64, 192], [16, 64, 96], [16, 64, 48], [16, 64, 24]]           0       \n",
      "    Conv1D-124                                             [[16, 64, 768]]                                                                                 [16, 64, 768]                                             20,544     \n",
      "   Hardswish-87                                            [[16, 64, 768]]                                                                                 [16, 64, 768]                                                0       \n",
      "    Conv1D-125                                             [[16, 64, 384]]                                                                                 [16, 64, 384]                                             20,544     \n",
      "   Hardswish-88                                            [[16, 64, 384]]                                                                                 [16, 64, 384]                                                0       \n",
      "    Conv1D-126                                             [[16, 64, 192]]                                                                                 [16, 64, 192]                                             20,544     \n",
      "   Hardswish-89                                            [[16, 64, 192]]                                                                                 [16, 64, 192]                                                0       \n",
      "    Conv1D-127                                             [[16, 64, 96]]                                                                                  [16, 64, 96]                                              20,544     \n",
      "   Hardswish-90                                            [[16, 64, 96]]                                                                                  [16, 64, 96]                                                 0       \n",
      "    Conv1D-128                                             [[16, 64, 48]]                                                                                  [16, 64, 48]                                              20,544     \n",
      "   Hardswish-91                                            [[16, 64, 48]]                                                                                  [16, 64, 48]                                                 0       \n",
      "    Conv1D-129                                             [[16, 64, 24]]                                                                                  [16, 64, 24]                                              20,544     \n",
      "   Hardswish-92                                            [[16, 64, 24]]                                                                                  [16, 64, 24]                                                 0       \n",
      "Conv1DTranspose-25                                         [[16, 64, 24]]                                                                                  [16, 64, 48]                                              16,448     \n",
      "Conv1DTranspose-24                                         [[16, 64, 48]]                                                                                  [16, 64, 96]                                              16,448     \n",
      "Conv1DTranspose-23                                         [[16, 64, 96]]                                                                                  [16, 64, 192]                                             16,448     \n",
      "Conv1DTranspose-22                                         [[16, 64, 192]]                                                                                 [16, 64, 384]                                             16,448     \n",
      "Conv1DTranspose-21                                         [[16, 64, 384]]                                                                                 [16, 64, 768]                                             16,448     \n",
      "    UpStage-1         [[[16, 64, 768], [16, 64, 384], [16, 64, 192], [16, 64, 96], [16, 64, 48], [16, 64, 24]]]                                            [16, 64, 768]                                                0       \n",
      "    Conv1D-130                                             [[16, 64, 768]]                                                                                 [16, 1, 768]                                                65       \n",
      "==================================================================================================================================================================================================================================\n",
      "Total params: 47,366,269\n",
      "Trainable params: 47,344,509\n",
      "Non-trainable params: 21,760\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Input size (MB): 1.03\n",
      "Forward/backward pass size (MB): 1793.16\n",
      "Params size (MB): 180.69\n",
      "Estimated Total Size (MB): 1974.88\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 47366269, 'trainable_params': 47344509}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 用eval函数生成指定名称的模型，并输出摘要\n",
    "model = eval(MODEL_NAME)()\n",
    "paddle.summary(model, input_size=(BATCH_SIZE, INPUT_DEPTH, TRAIN_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load best_model\n"
     ]
    }
   ],
   "source": [
    "# 训练完成后，加载最优（或指定）的模型参数。\r\n",
    "if TRAIN:\r\n",
    "    train(model)\r\n",
    "params = paddle.load('Models/%s/model.pdparams'%USE_MODEL)\r\n",
    "print('Load', USE_MODEL)\r\n",
    "model.set_state_dict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([80309., 64369., 35717., 24321., 21676., 21023., 22965., 30855.,\n",
       "        36531., 28593.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 预测结果，并对结果统计信息进行可视化。压缩保存当前的模型、代码等。\r\n",
    "if not os.path.exists(OUTPUT_PATH):\r\n",
    "    os.makedirs(OUTPUT_PATH)\r\n",
    "else:\r\n",
    "    os.system('rm -rf %s/*.*'%OUTPUT_PATH)\r\n",
    "Yp = predict(model, test_dataset)\r\n",
    "if USE_POST_PROCESS:\r\n",
    "    Yp = [(1-np.cos(X*np.pi))/2 for X in Yp]\r\n",
    "for data_i, (data, Q) in enumerate(zip(test_dataset, Yp)):\r\n",
    "    save_path = os.path.join(OUTPUT_PATH, '%d.predict.txt'%(data_i+1))\r\n",
    "    with open(save_path, 'w') as f:\r\n",
    "        for p in Q:\r\n",
    "            f.write('%.8f\\n'%p)\r\n",
    "# if os.path.exists('predict.files.zip'):\r\n",
    "os.system('rm -rf *.zip')\r\n",
    "os.system('zip -qr predict.files.zip %s && rm -rf %s'%(OUTPUT_PATH, OUTPUT_PATH))\r\n",
    "os.system('cd Models && zip -qr %s.zip %s vdl_log && mv %s.zip ../'%(USE_MODEL, USE_MODEL, USE_MODEL))\r\n",
    "os.system('zip -qr source_all.zip *.py *.ipynb work/ %s.zip work/'%USE_MODEL)\r\n",
    "plt.hist(np.concatenate(Yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
